---
layout: post
title: 딥러닝이란 무엇인가?
description: |
  1.1 인공 지능과 머신 러닝, 딥러닝 <br>

  1.2 딥러닝 이전: 머신 러닝의 간략한 역사(생략) <br>

  1.3 왜 딥러닝일까? 왜 지금일까?(생략)
sitemap: false
hide_last_modified: true
---
## 1.1 인공 지능과 머신 러닝, 딥러닝
**이 글은 [케라스 창시자에게 배우는 딥러닝]책을 학습하며 내용을 정리한 글입니다.**

AI를 학습하기 앞 서 사용하는 용어를 정리하자

![800x400](/assets/img/blog/ai_ml_dl.jpg "인공 지능, 머신 러닝 그리고 딥러닝")

### 인공지능
인공 지능은 초기 컴퓨터 과학 분야의 종사자의 "컴퓨터가 '생각'할 수 있는가?"라는 질문을 하면서 시작

인공지능의 간결한 정의: "보통의 사람이 수행하는 지능적인 작업을 자동화하기 위한 연구 활동"

이처럼 AI는 머신 러닝과 딥러닝을 **포괄**하는 종합적인 분야이다. 인공지능은 명시적인 규칙을 충분하게 많이 만들어 인간 수준의 인공 지능을 구현하려 한 **심볼릭 AI(symbolic AI)**도 포함한다.

이미지 분류, 음성 인식, 언어 번역 같은 복잡하고 분명하지 않은 문제를 해결하기 위한 명확한 규칙을 찾는 것은 아주 어려운 일이다. 이런 심볼릭 AI를 대체하기 위한 새로운 방법인 **머신 러닝**이 등장.
### 머신러닝
![400x300](/assets/img/blog/ml.jpg "머신 러닝: 새로운 프로그래밍 패러다임")

전통적인 프로그래밍 방식: 프로그래머가 입력 데이터를 적절한 해답으로 바꾸기 위해 따라야 하는 규칙(컴퓨터 프로그램)을 작성하는 것이다.

머신 러닝: 입력 데이터와 상응하는 해답을 보고 규칙을 찾는다.

머신 러닝 시스템은 명시적으로 프로그래밍되는 것이 아니라 **훈련(training)**된다.

#### 데이터에서 표현을 학습하기
**딥러닝**을 정의하고 다른 머신 러닝 방식과의 차이점을 이해하기 위해선 머신러닝 알고리즘이 하는 일이 무엇인지 알아야 한다.

머신 러닝을 하기 위해서는 다음 세 가지가 필요하다.

**입력 데이터 포인트**

**기대 출력**

**알고리즘의 성능을 측정하는 방법**: 알고리즘의 현재 출력과 기대 출력 간의 차이를 결정하기 위해 필요하다. 측정값은 알고리즘의 작동 방식을 교정하기 위한 신호로 다시 피드백한다. 이러한 수정 단계를 **학습(learning)**이라고 한다.

머신 러닝과 딥러닝의 핵심 문제는 기대 출력에 가까워지도록 입력 데이터의 유용한 **표현(representation)**을 학습하는 것이다.
**표현**이란 핵심적으로 말하면 데이터를 인코딩(encoding)하거나 표현하기 위해 데이터를 바라보는 다른 방법이다.

e.g.g. 컬러 이미지 : RGB포맷 or HSV 포맷(색상-채도-명도)로 인코딩 가능

컬러 이미지란 같은 데이터의 두 가지 다른 표현이다. '이미지에 있는 모든 빨간색 픽셀을 선택'하는 문제는 RGB포맷에서는 쉬움. 반면 '이미지의 채도를 낮추는'것은 HSV 포맷이 더 쉬움.

이러한 데이터 변한은 당면한 문제를 더 쉽게 해결할 수 있도록 만들어 준다.

#### 딥러닝에서 '딥'이란 무엇일까?
딥러닝: 머신 러닝의 특정한 한 분야로서 연속된 **층(layer)**에서 학습하는데 강점이 있으며, 데이터로부터 표현을 학습하는 새로운 방식이다.

**딥러닝**의 **딥(deep)**이란 그냥 연속된 층으로 표현을 학습한다는 개념

모델을 만드는 데 얼마나 많은 층을 사용했는지가 그 모델의 **깊이**가 됨

최근의 딥러닝 모델은 표현 학습을 위해 수십, 수백 개의 연속된 층을 가지고 있음.
한편 다른 머신 러닝 접근 방법은 1~2개의 데이터 표현 층을 학습하는 경향이 있음. 이러한 방식을 **얕은 학습(shallow learning)**이라고 한다.

딥러닝에서는 말 그대로 층을 겹겹이 쌓아 올려 구성한 **신경망(neural network)**이라는 모델을 사용하여 층 기반 표현을 학습

- 몇 개의 층으로 이루어진 네트워크가 이미지 안의 숫자를 인식하기 위한 과정을 살펴보자
![400x200](/assets/img/blog/deep-neural-network.jpg "숫자 분류를 위한 심층 신경망(deep neural network)")
![800x400](/assets/img/blog/num_classifier.jpg "숫자 분류 모델이 학습한 표현")

그림에서 볼 수 있듯이 최종 출력에 대해 점점 더 많은 정보를 가지지만 원본 이미지와는 점점 더 다른 표현으로 숫자 이미지가 변환된다.

딥러닝: 데이터 표현을 학습하기 위한 다단계 처리 방식

#### 그림 3개로 딥러닝의 작동 원리 이해하기
층이 입력 데이터를 처리하는 방식은 일련의 숫자로 이루어진 층의 **가중치(weight)**에 저장되어 있음. 가중치=**파라미터(parameter)**
이런 맥락으로 보면 **학습**은 주어진 입력을 정확한 타깃에 매핑하기 위해 신경망의 모든 층에 있는 가중치 값을 찾는 것을 의미

![400x200](/assets/img/blog/neural-network-parameter.jpg "신경망은 가중치를 파라미터로 가진다")

신경망의 출력을 제어하려면 출력이 기대하는 것보다 얼마나 벗어났는지 측정해야 한다. 이는 신경망의 **손실 함수(loss function)**가 담당하는 일이다. 손실 함수를 **목적 함수(objective function)** 또는 **비용 함수(cost function)**라고도 부른다. 신경망의 한 샘플에 대해 얼마나 잘 예측했는지 측정하기 위해 손실 함수가 신경망의 예측과 진짜 타깃(신경망의 출력으로 기대하는 값)의 차이를 점수로 계산한다.

![400x300](/assets/img/blog/loss-function.jpg "손실 함수가 신경망의 출력 품질을 측정")

기본적인 딥러닝 방식은 이 점수를 피드백 신호로 사용하여 현재 샘플의 손실 점수가 감소되는 방향으로 가중치 값을 조금씩 수정하는 것이다.
이런 수정 과정은 딥러닝의 핵심 알고리즘인 **역전파(backpropagation)**알고리즘을 구현한 **옵티마이저(optimizer)**가 담당한다.

![400x300](/assets/img/blog/loss-score-used-by-signal.jpg "손실 점수를 피드백 신호로 사용하여 가중치 조정")

초기에는 네트워크(신경망)의 가중치가 랜덤한 값으로 할당되므로 랜덤한 변환을 연속적으로 수행한다. 출력은 기대한 값과 멀고 손실 점수가 매우 높을 것이다. 네트워크(신경망)가 모든 샘플을 처리하면서 가중치가 조금씩 올바른 방향으로 조정되고 손실 점수가 감소한다.

이를 **훈련 반복(training loop)**이라고 하며, 충분한 횟수만큼 반복하면 손실 함수를 최소화하는 가중치 값을 산출한다. 최소한의 손실을 내는 네트워크(신경망)가 타깃에 가능한 가장 가까운 출력을 만드는 모델이 된다.

## 1.2 딥러닝 이전: 머신 러닝의 간략한 역사(생략)

## 1.3 왜 딥러닝일까? 왜 지금일까?(생략)